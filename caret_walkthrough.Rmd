---
title: "Caret Walkthrough"
output: html_notebook
---

```{r}
library(tidyverse)
library(magrittr)
library(caret)
```

Import the data
```{r}
train <- read.csv("train_u6lujuX_CVtuZ9i.csv", stringsAsFactors = T)
# train <- read_csv("train_u6lujuX_CVtuZ9i.csv") # this yields almost twice as many NAs
glimpse(train)
```

We need to pre-process our data before we can use it for modeling. Let’s check if the data has any missing values:
```{r}
sum(is.na(train))
# 86.
```

Next, let us use Caret to impute these missing values using KNN algorithm. We will predict these missing values based on other attributes for that row. Also, we’ll scale and center the numerical data by using the convenient preprocess() in Caret.

```{r}
#Imputing missing values using KNN.Also centering and scaling numerical columns
preProcValues <- preProcess(train, method = c("knnImpute","center","scale"))

# From what I can tell, the preProcess function creates a list, but I don't really know with what or why

library('RANN') # this is the KNN package
train_processed_raw <- predict(preProcValues, train)
sum(is.na(train_processed_raw))
#[1] 0
```

```{r}
id <- train_processed_raw$Loan_ID # saving the id elsewhere (for dummy?)

train_processed <- train_processed_raw %>% 
  mutate(Loan_Status = if_else(Loan_Status == 'N', 0,1), # make output numeric
         Loan_ID = NULL # not sure why I'm doing this. Something to do with creating dummy vars?
         )

glimpse(train_processed)
```

Now, creating dummy variables using one hot encoding:

```{r}
#Converting every categorical variable to numerical using dummy variables
# I guess that it creates a list that I don't understand
dmy <- dummyVars(" ~ .", data = train_processed, fullRank = T)
str(dmy)
summary(dmy)
# not sure how this works
train_transformed <- data.frame(predict(dmy, newdata = train_processed)) %>% 
  mutate(Loan_Status = as.factor(Loan_Status))

glimpse(train_transformed)
```

```{r}
#Spliting training set into two parts based on outcome: 75% and 25%
index <- createDataPartition(train_transformed$Loan_Status, p=0.75, list=FALSE)

# trainSeta <- train_transformed[ index,]
trainSet <- train_transformed %>% slice(index)

# testSet <- train_transformed[-index,]
testSet <- train_transformed %>% slice(-index)

str(trainSet)
```

[feature seletion](https://www.analyticsvidhya.com/blog/2016/12/introduction-to-feature-selection-methods-with-an-example-or-how-to-select-the-right-variables/)

```{r}
#Feature selection using rfe in caret
control <- rfeControl(functions = rfFuncs,
                   method = "repeatedcv",
                   repeats = 3,
                   verbose = FALSE)
outcomeName <- 'Loan_Status'
predictors <- names(trainSet)[!names(trainSet) %in% outcomeName]
Loan_Pred_Profile <- rfe(trainSet[,predictors], trainSet[,outcomeName],
                      rfeControl = control)
Loan_Pred_Profile
#Recursive feature selection
#Outer resampling method: Cross-Validated (10 fold, repeated 3 times)
#Resampling performance over subset size:
#  Variables Accuracy  Kappa AccuracySD KappaSD Selected
#4   0.7737 0.4127    0.03707 0.09962        
#8   0.7874 0.4317    0.03833 0.11168        
#16   0.7903 0.4527    0.04159 0.11526        
#18   0.7882 0.4431    0.03615 0.10812        
#The top 5 variables (out of 16):
#  Credit_History, LoanAmount, Loan_Amount_Term, ApplicantIncome, CoapplicantIncome
#Taking only the top 5 predictors
predictors<-c("Credit_History", "LoanAmount", "Loan_Amount_Term", "ApplicantIncome", "CoapplicantIncome")
```

This is the cool part of caret. It provides standard syntax for over 200 different [models](http://topepo.github.io/caret/available-models.html).

```{r}
model_gbm <- train(trainSet[, predictors], trainSet[, outcomeName], method = 'gbm') # GBM
model_rf <- train(trainSet[, predictors], trainSet[, outcomeName], method = 'rf') # random forest
model_nnet <- train(trainSet[, predictors], trainSet[, outcomeName], method = 'nnet') # nural net
model_glm <- train(trainSet[, predictors], trainSet[, outcomeName], method = 'glm') # logistic regression
```


Model tuning. I'm not exactly sure what this does. It's used in the turning areas below. The docs say: 
"The resampling technique used for evaluating the performance of the model using a set of parameters in Caret by default is bootstrap, but it provides alternatives for using k-fold, repeated k-fold as well as Leave-one-out cross validation (LOOCV) which can be specified using trainControl(). In this example, we’ll be using 5-Fold cross-validation repeated 5 times."
```{r}
fitControl <- trainControl(
  method = "repeatedcv",
  number = 5,
  repeats = 5)
str(fitControl)
```

t
```{r}
# get details of the model
modelLookup(model='gbm')

#Creating grid
grid <- expand.grid(n.trees=c(10,20,50,100,500,1000),shrinkage=c(0.01,0.05,0.1,0.5),n.minobsinnode = c(3,5,10),interaction.depth=c(1,5,10))

# training the model
# So this is like the model we used above, but we added extra parameters: the control, which we defined with fitControl as a 5 fold cross validation repeated 5 times. Secondly, using the grid we defined above, we are running the model with different tweaks of how the model works. 
# this takes a lot longer to run since it needs to work against the grid and the additional controls
model_gbm<-train(trainSet[,predictors],trainSet[,outcomeName],method='gbm',trControl=fitControl,tuneGrid=grid)

# summarizing the model
print(model_gbm)
```

```{r}
plot()
```

6.2. Using tuneLength

Instead, of specifying the exact values for each parameter for tuning we can simply ask it to use any number of possible values for each tuning parameter through tuneLength. Let’s try an example using tuneLength=10.

```{r}
#using tune length
model_gbm_tl <- train(trainSet[,predictors],
                      trainSet[,outcomeName],
                      method='gbm',
                      trControl=fitControl,
                      tuneLength=10)
print(model_gbm_tl)
plot(model_gbm_tl)
```

7. Variable importance estimation using caret

Caret also makes the variable importance estimates accessible with the use of varImp() for any model. Let’s have a look at the variable importance for all the four models that we created:

```{r}
#Variable Importance
varImp(object=model_gbm)

plot(varImp(object=model_gbm),main="GBM - Variable Importance")
```

